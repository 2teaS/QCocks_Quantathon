{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c71a3a2-d466-4f51-929b-bc07dcbf6669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ionqvision.ansatze.ansatz_library import AngleEncoder\n",
    "\n",
    "encoder = AngleEncoder(num_qubits=4)\n",
    "encoder.draw(\"mpl\")\n",
    "from ionqvision.ansatze.ansatz_library import QCNNAnsatz\n",
    "\n",
    "ansatz = QCNNAnsatz(num_qubits=4)\n",
    "ansatz.draw(\"mpl\")\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "\n",
    "# Measure the expectation value of X_0, Y_0, Z_0\n",
    "quantum_features = [\n",
    "    SparsePauliOp([\"IIIX\"]), \n",
    "    SparsePauliOp([\"IIIY\"]), \n",
    "    SparsePauliOp([\"IIIZ\"])\n",
    "]\n",
    "from ionqvision.modules import BinaryMNISTClassifier\n",
    "\n",
    "# Set up your classifier and inspect its architecture\n",
    "# BinaryMNISTClassifier uses the encoder, quantum ansatz, and quantum features\n",
    "# It combines the quantum and classical neural network layers for binary classification\n",
    "classifier = BinaryMNISTClassifier(encoder, ansatz, quantum_features); classifier\n",
    "import logging\n",
    "# Suppress unnecessary logging to focus on the critical outputs during training\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "# Check out your quantum layer\n",
    "classifier.quantum_layer.layer_qc.draw(\"mpl\")\n",
    "# Verify the images loaded correctly\n",
    "classifier.visualize_batch()\n",
    "%%time\n",
    "# Get a (pre-processed) training and test set\n",
    "# In this case, we are using 300 images for training and 100 for testing\n",
    "train_set, test_set = classifier.get_train_test_set(train_size=300, test_size=100)\n",
    "\n",
    "# Configure model training hyper parameters\n",
    "config = {\n",
    "    \"epochs\": 10,  # Number of passes through the entire training dataset, increased epochs can help the model learn complex patterns\n",
    "    \"lr\": 0.01,    # Learning rate for the Adam optimizer\n",
    "    \"batch_size\": 55,  # Number of images in each training batch\n",
    "    \"betas\": (0.9, 0.99),  # Parameters for controlling momentum and smoothing\n",
    "    \"weight_decay\": 1e-3,  # Parameter to avoid overfitting\n",
    "    \"clip_grad\": True,     # Gradient clipping to prevent exploding gradients\n",
    "    \"log_interval\": 6,     # Interval for logging during training\n",
    "}\n",
    "\n",
    "# Train and plot the results\n",
    "classifier.train_module(train_set, test_set, config)\n",
    "classifier.plot_training_progress()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [ionqvision]",
   "language": "python",
   "name": "python3_ionq_v_u41rxp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
